<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Yoga Pose Training Tool</title>
    <!-- Load Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0/dist/tf.min.js"></script>
    <!-- Load Pose Detection library -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.0.0/dist/pose-detection.min.js"></script>
    <style>
        /* Custom styles for canvas overlay */
        .canvas-container {
            position: relative;
            width: 100%;
            max-width: 800px;
            margin: 0 auto;
        }
        #video, #canvas, #image-output {
            display: none; /* Controlled by JS */
            border-radius: 0.5rem;
            width: 100%;
            height: auto;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 10;
        }
        #video.active, #image-output.active, #canvas.active {
            display: block;
        }
        .mode-button {
            transition: all 0.2s;
        }
        .mode-button.active {
            @apply ring-4 ring-indigo-500 ring-opacity-50 shadow-lg bg-indigo-600 text-white;
        }
        /* Mirroring for the live camera feed */
        #video.camera-mode {
            transform: scaleX(-1);
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen font-sans p-4">

    <header class="text-center py-4 mb-6 bg-white shadow-md rounded-lg">
        <h1 class="text-3xl font-extrabold text-indigo-700">Yoga Pose Training Data Collector For Model Training</h1>
        <p class="text-sm text-gray-500 mt-1" id="persistence-status">
            Data Persistence: <strong>Storage</strong> (Download the json and send the collected data)
        </p>
    </header>

    <main class="grid lg:grid-cols-3 gap-6">

        <!-- Left Panel: Video/Image Input & Canvas -->
        <div class="lg:col-span-2 bg-white p-6 rounded-xl shadow-xl">
            <h2 class="text-xl font-semibold mb-4 text-gray-700">Live Pose Detection</h2>

            <div class="canvas-container shadow-2xl bg-gray-900 rounded-lg overflow-hidden">
                <video id="video" autoplay muted playsinline class="camera-mode"></video>
                <img id="image-output" alt="Uploaded or Video Frame" class="object-contain" style="max-height: 80vh;">
                <!-- Canvas overlay for drawing the skeleton -->
                <canvas id="canvas"></canvas>
            </div>

            <div class="flex flex-col sm:flex-row gap-4 mt-6 items-center">
                <!-- File Input (Hidden, triggered by JS) -->
                <input type="file" id="file-input" accept="image/*,video/*" class="hidden">

                <!-- Video Controls -->
                <button id="video-play-pause-btn" class="hidden bg-yellow-500 hover:bg-yellow-600 text-white font-bold py-2 px-4 rounded-lg transition" disabled>
                    <span id="video-control-text">Play</span>
                </button>

                <!-- Status Message -->
                <p id="status" class="text-sm text-gray-500 flex-grow text-center">Initializing...</p>
            </div>
        </div>

        <!-- Right Panel: Controls, Reference, and Data -->
        <div class="lg:col-span-1 flex flex-col gap-6">

            <!-- Mode Selector -->
            <div class="bg-white p-6 rounded-xl shadow-xl">
                <h3 class="text-lg font-medium mb-3 text-gray-700">Training Mode</h3>
                <div class="grid grid-cols-3 gap-2">
                    <button id="mode-camera" data-mode="camera" class="mode-button bg-gray-200 hover:bg-gray-300 text-gray-800 font-bold py-2 rounded-lg text-sm">Camera (Live)</button>
                    <button id="mode-image" data-mode="image" class="mode-button bg-gray-200 hover:bg-gray-300 text-gray-800 font-bold py-2 rounded-lg text-sm">Image</button>
                    <button id="mode-video" data-mode="video" class="mode-button bg-gray-200 hover:bg-gray-300 text-gray-800 font-bold py-2 rounded-lg text-sm">Video</button>
                </div>
            </div>

            <!-- Pose Selector and Actions -->
            <div class="bg-white p-6 rounded-xl shadow-xl">
                <h3 class="text-lg font-medium mb-3 text-gray-700">Pose Label & Action</h3>
                
                <label for="pose-select" class="block text-sm font-medium text-gray-700 mb-2">Current Pose:</label>
                <select id="pose-select" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-indigo-500 focus:border-indigo-500 sm:text-sm rounded-md shadow-sm">
                    <option value="Tree" selected>Tree Pose (Vrksasana)</option>
                    <option value="Warrior II">Warrior II (Virabhadrasana II)</option>
                    <option value="Warrior I">Warrior I (Virabhadrasana I)</option>
                    <option value="Mountain">Mountain Pose (Tadasana)</option>
                    <option value="Triangle">Triangle Pose (Trikonasana)</option>
                    <option value="Downward Dog">Downward Dog (Adho Mukha Svanasana)</option>
                </select>

                <button id="save-pose-btn" class="w-full mt-4 bg-green-500 hover:bg-green-600 text-white font-bold py-3 px-4 rounded-lg transition shadow-md hover:shadow-lg disabled:opacity-50" disabled>
                    Save Pose Sample (0)
                </button>

                <div class="mt-4 text-center text-sm font-medium text-gray-600">
                    Total Samples Collected: <span id="sample-count" class="font-bold text-indigo-600">0</span>
                </div>
                
                <div class="grid grid-cols-2 gap-2 mt-4">
                    <button id="clear-last-btn" class="bg-red-400 hover:bg-red-500 text-white font-bold py-3 px-2 rounded-lg transition shadow-md hover:shadow-lg disabled:opacity-50 text-sm" disabled>
                        Clear Last Sample
                    </button>
                    <button id="clear-all-btn" class="bg-red-600 hover:bg-red-700 text-white font-bold py-3 px-2 rounded-lg transition shadow-md hover:shadow-lg disabled:opacity-50 text-sm" disabled>
                        Clear ALL Data
                    </button>
                </div>

                <button id="download-dataset-btn" class="w-full mt-4 bg-indigo-500 hover:bg-indigo-600 text-white font-bold py-3 px-4 rounded-lg transition shadow-md hover:shadow-lg disabled:opacity-50" disabled>
                    Download Dataset (.json)
                </button>
            </div>

            <!-- Reference Image -->
            <div class="bg-white p-6 rounded-xl shadow-xl">
                <h3 class="text-lg font-medium mb-3 text-gray-700">Reference Pose</h3>
                <img id="reference-img" src="" alt="Reference Image" class="w-full h-auto rounded-lg object-cover shadow-inner bg-gray-200">
            </div>

        </div>
    </main>
    <footer class="mt-8 py-4 text-center text-gray-500 text-sm">
        <p>Powered by TensorFlow.js and MoveNet. Data stored locally on your device.</p>
        <br>
        <p>Yogasthali 2025. All rights reserved.</p>
    </footer>

    <script>
        // --- GLOBAL STATE ---
        let detector = null;
        let animationFrameId = null;
        let currentMode = null; // 'camera', 'image', 'video'
        let dataset = [];
        let video = document.getElementById('video');
        let imageOutput = document.getElementById('image-output');
        let canvas = document.getElementById('canvas');
        let ctx = canvas.getContext('2d');

        // UI elements
        const statusEl = document.getElementById('status');
        const saveBtn = document.getElementById('save-pose-btn');
        const downloadBtn = document.getElementById('download-dataset-btn');
        const poseSelect = document.getElementById('pose-select');
        const sampleCountEl = document.getElementById('sample-count');
        const videoPlayPauseBtn = document.getElementById('video-play-pause-btn');
        const fileInput = document.getElementById('file-input');
        const clearLastBtn = document.getElementById('clear-last-btn');
        const clearAllBtn = document.getElementById('clear-all-btn');
        
        const STORAGE_KEY = 'yogaPoseDataset'; // Key for localStorage

        // Pose-to-Reference Image Map (Placeholder URLs)
        const REFERENCE_IMAGES = {
            'Tree': 'tree.jpg',
            'Warrior II': 'warrior2.jpg',
            'Warrior I': 'warrior1.jpg',
            'Mountain': 'tada1.jpg',
            'Triangle': 'triangle.jpg',
            'Downward Dog': 'adhomukh.gif',
        };

        // Keypoint connections for drawing the skeleton
        const POSE_CONNECTIONS = [
            [0, 1], [0, 2], [1, 3], [2, 4], // Head & Shoulders
            [5, 6], [5, 7], [7, 9], [6, 8], [8, 10], // Arms
            [5, 11], [6, 12], [11, 12], // Torso
            [11, 13], [13, 15], [12, 14], [14, 16] // Legs
        ];


        // --- DATA FUNCTIONS (LOCAL STORAGE) ---

        /** Updates the UI sample count. */
        const updateSampleCount = () => {
            sampleCountEl.textContent = dataset.length;
            saveBtn.textContent = `Save Pose Sample (${dataset.length})`;
            saveBtn.disabled = detector === null; // Enable only after model loads
            downloadBtn.disabled = dataset.length === 0;
            clearLastBtn.disabled = dataset.length === 0;
            clearAllBtn.disabled = dataset.length === 0;
        };

        /** Loads data from localStorage. */
        const loadInitialData = () => {
            try {
                const storedData = localStorage.getItem(STORAGE_KEY);
                if (storedData) {
                    dataset = JSON.parse(storedData);
                }
            } catch (e) {
                console.error("Error loading data from localStorage:", e);
                // Fallback to empty array
                dataset = [];
            }
            updateSampleCount();
            statusEl.textContent = `Model Ready. ${dataset.length} samples loaded from local storage.`;
        };
        
        /** Saves the current dataset array to localStorage. */
        const saveDatasetToLocalStorage = () => {
            try {
                localStorage.setItem(STORAGE_KEY, JSON.stringify(dataset));
            } catch (error) {
                console.error("Local Storage Save Error:", error);
                statusEl.textContent = "ERROR: Failed to save sample to local storage. Browser storage may be full.";
            }
        };


        // --- MODEL & RENDERING FUNCTIONS (UNCHANGED) ---

        /** Initializes the MoveNet detector. */
        async function setupDetector() {
            statusEl.textContent = "Loading MoveNet model...";
            const modelConfig = {
                modelType: poseDetection.SupportedModels.MoveNet,
                config: { modelUrl: 'https://tfhub.dev/google/tfjs-model/movenet/singlepose/lightning/4', enableSmoothing: true }
            };
            detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, modelConfig.config);
            statusEl.textContent = "MoveNet Lightning Detector Ready. Select a mode.";
        }

        /** Draws the skeleton on the canvas. */
        function drawKeypoints(pose) {
            if (!pose || !pose.keypoints) return;

            const keypoints = pose.keypoints;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.strokeStyle = '#00FF00'; // green skeleton
            ctx.fillStyle = '#00FF00';   // green joints

            ctx.lineWidth = 2;

            // Draw keypoints (dots)
            for (let i = 0; i < keypoints.length; i++) {
                const kp = keypoints[i];
                if (kp.score > 0.3) {
                    ctx.beginPath();
                    ctx.arc(kp.x, kp.y, 5, 0, 2 * Math.PI);
                    ctx.fill();
                }
            }

            // Draw connections (lines)
            for (let i = 0; i < POSE_CONNECTIONS.length; i++) {
                const [index1, index2] = POSE_CONNECTIONS[i];
                const kp1 = keypoints[index1];
                const kp2 = keypoints[index2];

                if (kp1.score > 0.3 && kp2.score > 0.3) {
                    ctx.beginPath();
                    ctx.moveTo(kp1.x, kp1.y);
                    ctx.lineTo(kp2.x, kp2.y);
                    ctx.stroke();
                }
            }
        }

        /** The main recursive loop for continuous pose detection (Camera/Video). */
        async function poseLoop() {
            let inputElement = video; 

            if (inputElement.readyState < 2 || !detector) {
                animationFrameId = requestAnimationFrame(poseLoop);
                return;
            }

            // Flip horizontally only for live camera feed
            const poses = await detector.estimatePoses(inputElement, { flipHorizontal: currentMode === 'camera' });
            
            if (poses && poses.length > 0) {
                // Resize canvas to match the input element's dimensions
                canvas.width = inputElement.videoWidth || inputElement.naturalWidth || inputElement.width;
                canvas.height = inputElement.videoHeight || inputElement.naturalHeight || inputElement.height;
                
                // Flip the canvas content horizontally for the mirrored camera view
                if (currentMode === 'camera') {
                    ctx.save();
                    ctx.scale(-1, 1);
                    ctx.translate(-canvas.width, 0);
                    drawKeypoints(poses[0]);
                    ctx.restore();
                } else {
                    drawKeypoints(poses[0]);
                }
                
                // Store the latest detected pose object for saving
                window.latestPose = poses[0];

            } else {
                ctx.clearRect(0, 0, canvas.width, canvas.height);
            }

            animationFrameId = requestAnimationFrame(poseLoop);
        }

        /** Detects pose in a static image. */
        async function detectPoseInImage(imgElement) {
            statusEl.textContent = "Detecting pose in image...";
            if (!detector) return;
            
            // Wait for image to load
            await new Promise(resolve => imgElement.onload = resolve);
            
            // Set canvas size to match image
            canvas.width = imgElement.naturalWidth;
            canvas.height = imgElement.naturalHeight;
            
            // Scale the canvas container to match the displayed image size for proper overlay alignment
            const ratio = imgElement.clientWidth / imgElement.naturalWidth;
            canvas.style.transform = `scale(${ratio})`;
            canvas.style.transformOrigin = 'top left';

            // Reset transform for drawing internally
            canvas.style.transform = 'none';

            const poses = await detector.estimatePoses(imgElement);

            if (poses && poses.length > 0) {
                drawKeypoints(poses[0]);
                window.latestPose = poses[0];
                saveBtn.disabled = false;
                statusEl.textContent = `Pose detected in image. Ready to save as "${poseSelect.value}".`;
            } else {
                statusEl.textContent = "No pose detected in the image.";
                saveBtn.disabled = true;
            }
        }

        // --- MODE SWITCHING & HANDLERS (UNCHANGED) ---

        /** Clears the current state and prepares UI for a new mode. */
        function resetApp() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
            }
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
            }
            video.classList.remove('active', 'camera-mode');
            imageOutput.classList.remove('active');
            canvas.classList.remove('active');
            videoPlayPauseBtn.classList.add('hidden');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            window.latestPose = null;
            saveBtn.disabled = true;
            fileInput.value = null; // Clear file input
        }

        /** Sets up the application for a new mode. */
        function setMode(mode) {
            if (currentMode === mode && mode !== 'image' && mode !== 'video') return; 

            resetApp();
            currentMode = mode;
            document.querySelectorAll('.mode-button').forEach(btn => {
                btn.classList.toggle('active', btn.dataset.mode === mode);
            });
            
            saveBtn.textContent = `Save Pose Sample (${dataset.length})`;

            if (mode === 'camera') {
                setupCamera();
                video.classList.add('active', 'camera-mode');
                canvas.classList.add('active');
            } else if (mode === 'image' || mode === 'video') {
                fileInput.setAttribute('accept', mode === 'image' ? 'image/*' : 'video/*');
                fileInput.click();
            }
        }

        /** Initializes the webcam feed. */
        async function setupCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    // Match canvas size to video size
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    poseLoop();
                    saveBtn.disabled = false;
                    statusEl.textContent = `Live Camera Ready. Pose: ${poseSelect.value}`;
                };
            } catch (error) {
                console.error("Camera access failed:", error);
                statusEl.textContent = "ERROR: Camera access denied or failed. Please check permissions.";
            }
        }

        /** Handles file uploads (Image or Video). */
        fileInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            if (!file) {
                currentMode = null;
                return;
            }

            const url = URL.createObjectURL(file);

            if (currentMode === 'image') {
                imageOutput.src = url;
                imageOutput.classList.add('active');
                canvas.classList.add('active');
                imageOutput.onload = () => detectPoseInImage(imageOutput);
            } else if (currentMode === 'video') {
                video.src = url;
                video.classList.remove('camera-mode');
                video.classList.add('active');
                canvas.classList.add('active');
                videoPlayPauseBtn.classList.remove('hidden');

                video.onloadedmetadata = () => {
                    video.pause(); // Start paused
                    document.getElementById('video-control-text').textContent = 'Play';
                    videoPlayPauseBtn.disabled = false;
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    saveBtn.disabled = true; // Disabled until a frame is paused
                    statusEl.textContent = "Video loaded. Press Play to start or Pause to save a frame.";
                };

                // The pose detection loop will only run when the video is paused/frozen.
            }
        });
        
        /** Handles video play/pause logic for video mode. */
        videoPlayPauseBtn.addEventListener('click', () => {
            if (video.paused) {
                video.play();
                document.getElementById('video-control-text').textContent = 'Pause';
                saveBtn.disabled = true; // Cannot save while playing
                if (animationFrameId) cancelAnimationFrame(animationFrameId); // Stop detection while playing
            } else {
                video.pause();
                document.getElementById('video-control-text').textContent = 'Play';
                poseLoop(); // Start detection on the frozen frame
                saveBtn.disabled = false; // Allow saving the frozen frame
            }
        });

        /** Updates the reference image based on the selected pose. */
        function updateReferenceImage() {
            const pose = poseSelect.value;
            document.getElementById('reference-img').src = REFERENCE_IMAGES[pose] || REFERENCE_IMAGES['Tree'];
        }

        // --- MAIN APPLICATION ACTIONS (UPDATED FOR LOCAL STORAGE) ---
          // --- DATA MANAGEMENT FUNCTIONS ---

        /** Removes the last sample collected. */
        clearLastBtn.addEventListener('click', () => {
            if (dataset.length > 0) {
                const lastSample = dataset.pop();
                saveDatasetToLocalStorage();
                updateSampleCount();
                statusEl.textContent = `Removed last saved sample for "${lastSample.label}". Total: ${dataset.length}`;
            } else {
                statusEl.textContent = "Dataset is already empty.";
            }
        });

        /** Clears the entire dataset. */
        clearAllBtn.addEventListener('click', () => {
            if (confirm("Are you sure you want to clear ALL collected data? This action cannot be undone.")) {
                dataset = [];
                localStorage.removeItem(STORAGE_KEY);
                updateSampleCount();
                statusEl.textContent = "All collected data has been cleared from local storage. Start fresh!";
            }
        });

        /** Saves the currently detected pose sample to dataset and localStorage. */
        saveBtn.addEventListener('click', () => {
            if (!window.latestPose) {
                statusEl.textContent = "No valid pose detected to save.";
                return;
            }
            if (!detector) {
                statusEl.textContent = "Error: Detector not ready. Cannot save data.";
                return;
            }

            const label = poseSelect.value;
            // Extract only necessary keypoint data (x, y, score)
            const keypoints = window.latestPose.keypoints.map(kp => ({ 
                x: kp.x, 
                y: kp.y, 
                score: kp.score 
            }));

            const newSample = { 
                label, 
                keypoints,
                timestamp: new Date().toISOString()
            };
            
            // 1. Add to in-memory array
            dataset.push(newSample);
            
            // 2. Save to Local Storage
            saveDatasetToLocalStorage();
            
            // 3. Update UI
            updateSampleCount();
            statusEl.textContent = `Sample saved successfully as "${label}"! Total: ${dataset.length}`;
        });

        /** Downloads the full dataset as a JSON file. */
        downloadBtn.addEventListener('click', () => {
            if (dataset.length === 0) {
                statusEl.textContent = "Dataset is empty. Save some poses first!";
                return;
            }
            const dataStr = JSON.stringify(dataset, null, 2);
            const blob = new Blob([dataStr], { type: "application/json" });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `yoga_dataset_${new Date().toISOString().slice(0, 10)}.json`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            statusEl.textContent = `Dataset of ${dataset.length} samples downloaded successfully.`;
        });

        // --- INITIALIZATION ---

        const setupApp = async () => {
            await setupDetector();
            loadInitialData();
            updateReferenceImage();
            
            // Set default mode to Camera if the model is ready
            setMode('camera'); 
        };

        // Attach listeners for UI changes
        document.querySelectorAll('.mode-button').forEach(btn => {
            btn.addEventListener('click', () => setMode(btn.dataset.mode));
        });

        poseSelect.addEventListener('change', updateReferenceImage);

        // Start the application setup
        setupApp();
    </script>
    
</body>
</html>